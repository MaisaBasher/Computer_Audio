Typing is an important skill, especially for visually impaired people as it creates more learning and employment opportunities for them. There are several online pla:orms (Typio, JAWs) that provide audio instructions to help visually impaired people learn typing. However, users still face some issues while learning typing even with this technology like- lack of feedback based on learners' performance and maintenance of good body posture, etc. Therefore, I am designing a system that will ensure efficient, enjoyable, and healthy learning experiences for visually impaired people by considering users' performance (finger and hand movement) and body posture (back, neck, arm posi7on) and sonifying proper instructions.



<img width="1026" alt="Screen Shot 2024-01-30 at 8 20 26 PM" src="https://github.com/MaisaBasher/Computer_Audio/assets/47857402/ccc32daf-f982-4a4d-b5d4-e476050de501">


User Manual:
There are two modes for my Touch type project.
1. Sensor Mode:
Once the user clicks the “Lesson_With_SensorData” buDon, the lesson plan will start playing.
Users are expected to click on the leDers based on the lesson plan in order. [if the wrong key is pressed, an error sound will play. However, don’t try to recMfy it since JSON data is generated by order index, therefore pressing extra keys will make the rest of the keys wrong]
Every Mme the user presses the key (based on the lesson plan), different JSON data is loaded with body posture and finger data. And the background sound would be modified based on that. AddiMonally, different error sounds (soWer than key error) will play for the wrong finger based on JSON data.
2. The Manual Mode:
The manual mode is meant for EvaluaMon where I can control the posture sound and play the Key and finger error sound based on the user's actual performance. I made sure to choose a slow lesson plan so that I could easily track user performance.
